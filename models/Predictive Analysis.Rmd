---
title: "Predicting Price Range"
output:
  html_document:
    df_print: paged
---

```{r libraries, include=FALSE}
library(knitr)
library(Hmisc)
library(reshape2)
library(data.table)
library(caret)
library(nnet)
library(data.table)
library(randomForest)
library(ranger)
library(corrplot)
library(factoextra)
library(FactoMineR)
library(psych);
library(tidyverse)
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
library(factoextra)
library(gridExtra)
```

```{r setup}
opts_chunk$set(echo = TRUE, eval = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55), tidy = TRUE)
```

```{r constants}
name = "Name"
city.name= "City"
cuisine.name= "Cuisine Style"
ranking.name= "Ranking"
rating.name= "Rating"
price.name= "Price Range"
number.reviews.name= "Number of Reviews"
review.name= "Reviews"
```


```{r load the data}
dat <- fread(input ='Data/TA_restaurants_curated_clean.csv', verbose = FALSE)
dat <- dat["Price Range" > 0]

#model preparation
dat[,c('Name','V1','Reviews','ID_TA','Cuisine Style')] <- NULL
dat[,'V1'] <- NULL

# convert city to numeric 
dat$City <- as.numeric(as.factor(dat$City))
```

```{r functions}
## Data size function
set.size<-function(n,dat){
  the.rows<-sample(x=1:nrow(dat),size=n,replace = FALSE)
  return(dat[the.rows,])
}

mlr <- function(data){ 
  require(nnet)
  require(caret)
  Model = 'Multinomial Logistic regression'
  `Sample Size` = nrow(data)
  mlr <- nnet::multinom(`Price Range`~ . ,data,family = 'binomial')
  pred = predict(mlr, newdata=test)
  cm <- caret::confusionMatrix(pred, test$`Price Range`)
  Accuracy <- round(cm$overall[[1]], 2)
  model.name <- paste0('models/Price Range/model_', Model,nrow(data),'.rda')
  conf.matrx.name <- paste0('models/Price Range/cm_', Model,nrow(data),'.rda')
  saveRDS(object = mlr, model.name)
  saveRDS(object = cm,conf.matrx.name )
  return(data.frame(Model,`Sample Size`,Accuracy))
}

rf.train <- function(data){ 
  Model = 'Random Forest'
  `Sample Size` = nrow(data)
  control <- trainControl(method = 'cv', number = 3,
                          search = 'random')
  
  grid <- expand.grid(mtry = c(20,80,160),splitrule = 'gini',
   min.node.size = 15)
  
  rf <- train(`Price Range` ~., data = data,method = 'ranger',
              trControl  = control, 
              tuneGrid = grid)
  
  pred = predict(rf, newdata=test)
  cm <- confusionMatrix(pred, test$`Price Range`)
  Accuracy <- round(cm$overall[[1]], 2)
  model.name <- paste0('models/Price Range/model_', Model,nrow(data),'.rda')
  conf.matrx.name <- paste0('models/Price Range/cm_', Model,nrow(data),'.rda')
  saveRDS(object = rf, model.name)
  saveRDS(object = cm,conf.matrx.name )
  return(data.frame(Model,`Sample Size`,Accuracy))
}

```

```{r correlation}
corr.dat <- cor(x = dat, y = dat[,c('Ranking', 'Rating','Price Range')])
corr.dat <- as.matrix(corr.dat[corr.dat[,'Price Range'] > 0.1,])
corrplot(corr.dat)
```

```{r splitting}

dat$`Price Range` <- as.factor(dat$`Price Range`)

n.values <- c(1000,5000,10000)
set.seed(5420)
split <- createDataPartition(dat$Rating,p = 0.8,list = FALSE,groups = 100)
train <- dat[split,]
test <- dat[-split,]

```

## Multinomial Regression Model
```{r multinomial regression model}

## base line model using train set 
rownames(corr.dat)
base.dat <- train %>%
select(rownames(corr.dat))
mlr(base.dat)

#base line model correlation 
base.dat$`Price Range` <- as.numeric(base.dat$`Price Range`) 
corr.base.dat <- cor(x = base.dat, y = base.dat)
corrplot(corr.base.dat,type = 'lower', diag = F)

# base line model logistics regression 
length(colnames(base.dat))
length(colnames(dat))

ml.result <- data.frame()
for (i in seq_along(n.values)){
  result <- mlr(data = set.size(n = n.values[i],dat = train))
  ml.result <- rbind(ml.result,result)
}


model <- glm(formula = `Price Range`~ ., family = binomial, data = train)

summary(model)

dat[, .(prop = .N / nrow(dat)), by = price.name]


```

## Random Forest Model

```{r random forest}


rf.results.1000 <- rf.train(data = set.size(n = 5000, dat = train))

rf.result <- data.frame()
for (i in seq_along(n.values)){
  result <- rf.train(data = set.size(n = n.values[i],dat = train))
  rf.result <- rbind(rf.result,result)
}
```

## Principle Component Analysis 

```{r PCA training}
train$`Price Range` <- as.numeric(train$`Price Range`)
pca_facto <- PCA(train,graph = F)
fviz_eig(pca_facto,ncp=11,addlabels = T)
```

```{r pca facto}
dat$`Price Range` <- as.numeric(dat$`Price Range`)
pca_facto <- PCA(dat,scale.unit = T,ncp = 6,graph = F)

dat.pca <- prcomp(dat, center = TRUE, scale. = TRUE)

ggbiplot(dat.pca)
ggbiplot(dat.pca, labels=rownames(dat.pca))
ggbiplot(dat.pca,ellipse=TRUE,obs.scale = 1, var.scale = 1)
```

```{r pca charts}
charts = lapply(1:6,FUN = function(x) fviz_contrib(pca_facto,choice = 'var',axes = x,title=paste('Dim',x)))
grid.arrange(grobs = charts,ncol=3,nrow=2)
```

```{r pca variables}
fviz_pca_var(X = pca_facto,col.var = 'contrib',gradient.cols = c('red'),col.circle = 'steelblue',repel = T)
```


