---
title: "Frameworks Final Project: Data Exloration"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,tidy = TRUE)
```

```{r libraries, message=FALSE, warning=FALSE}
library(knitr); library(Hmisc); library(DT); library(ggplot2); library(dplyr); 
library(reshape2); library(ggthemes); library(stringr); library(data.table); library(tidytext); library(recommenderlab); library(qdapTools); library(purrr); library(devtools)

```

```{r constants}
name = "Name"
city.name = "City"
cuisine.name = "Cuisine Style"
ranking.name = "Ranking"
rating.name = "Rating"
price.name = "Price Range"
number.reviews.name = "Number of Reviews"
review.name = "Reviews"
```

```{r load the data}
dat <- fread(input ='Data/TA_restaurants_curated_clean.csv', verbose = FALSE)

head(dat)
```


```{r analyze data, echo=FALSE}
city.dat <-  dat[,.(count = .N,percentage = round((.N /nrow(dat)) * 100,2), 
                  `Average Price Range` = mean(get(price.name)), 
                  `Average Rating` = mean(get(rating.name)), 
               `Average number of reviews` = mean(get(number.reviews.name))), 
               by= city.name]

setorder(city.dat, -count)

head(city.dat)
```


```{r }
ggplot(data = city.dat) + geom_bar(stat = 'identity', fill = 'firebrick4', 
                                     aes(x = reorder(City,count), y = count)) + 
 xlab('City') + ylab('Number of Restaurants')+coord_flip() + theme_classic()  + 
 ggtitle('Number of Restaurants per City')
```

```{r}
ggplot(data = city.dat) + geom_bar(stat = 'identity', fill = 'firebrick4', 
                                     aes(x = reorder(City,`Average Price Range`), y = `Average Price Range`)) + 
 xlab('City') + ylab('Average Price Range')+coord_flip() + theme_classic()  + 
 ggtitle('Most Expensive City by Restaurant')
```

```{r}
ggplot(data = city.dat) + geom_bar(stat = 'identity', fill = 'firebrick4', 
                                     aes(x = reorder(City,`Average number of reviews`), y = `Average number of reviews`)) + 
 xlab('City') + ylab('Average number of restaurants Reviews')+coord_flip() + theme_classic()  + 
 ggtitle('Which City has the Most Restaurants Reviews')
```

```{r}
ggplot(data = city.dat) + geom_bar(stat = 'identity', fill = 'firebrick4', 
                                     aes(x = reorder(City,`Average Rating`), y = `Average Rating`)) + 
 xlab('City') + ylab('Average Ratings')+coord_flip() + theme_classic()  + 
 ggtitle('Which City has the best Restaurants')
```

```{r text analysis looking at data}
calculations_rating= dat[,.( `Mean Rating`=mean(get(rating.name), na.rm=TRUE), `Standard Deviation`=sd(get(rating.name), na.rm=TRUE))]
calculations_rating

#Mean by city name
calculations_rating_city= dat[,.( `Mean Rating`=mean(get(rating.name), na.rm=TRUE), `Standard Deviation`=sd(get(rating.name), na.rm=TRUE)), by=city.name]
calculations_rating_city

#Median by city name
calculations_rating_city= dat[,.( `Median Rating`=median(get(rating.name), na.rm=TRUE)), by=city.name]
calculations_rating_city


ggplot(data=dat,aes(x=Rating))+
  geom_histogram(fill='blue')+
  theme_economist()

#Correlation between review rating and longer reviews
cor_char=cor(nchar(dat$Reviews),dat$Rating,use="complete.obs")
cor_char
cor.test(nchar(dat$Reviews),dat$Rating)

#Correlation with review length in words
cor_words= cor(str_count(string = dat$Reviews,pattern = '\\S+'),dat$Rating,use="complete.obs")
cor_words
cor.test(str_count(string = dat$Reviews,pattern = '\\S+'),dat$Rating)

#Correlation with review sentence
cor_sentence= cor(str_count(string = dat$Reviews,pattern = "[A-Za-z,;'\"\\s]+[^.!?]*[.?!]"),dat$Rating,use="complete.obs")
cor_sentence
cor.test(str_count(string = dat$Reviews,pattern = "[A-Za-z,;'\"\\s]+[^.!?]*[.?!]"),dat$Rating,use="complete.obs")


```
```{r text analysis sentiment bing lexicon}

#Using lexicon bing
subdat= dat[,c("V1", "Rating", "Reviews")]
subdat%>%
  group_by(V1)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)

#Positive and Negative Words in Reviews
subdat%>%
  group_by(V1)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)

#Proportion of Positive words in Reviews
subdat %>%
  select(V1,Reviews)%>%
  group_by(V1)%>%
  unnest_tokens(output=word,input=Reviews)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))


#Are positive reviews helpful?
subdat %>%
  select(V1,Reviews,Rating)%>%
  group_by(V1)%>%
  unnest_tokens(output=word,input=Reviews)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x=Rating,y=proportion,fill=sentiment))+geom_col()+theme_economist()

```

```{r text analysis sentiment nrc lexicon}
#Emotions in ratings
subdat%>%
  group_by(V1)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n),y=n,fill=sentiment))+geom_col()+guides(fill=F)+coord_flip()+theme_wsj()

#Rating and emotions
subdat%>%
  group_by(V1)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(V1,sentiment,Rating)%>%
  count()

#Correlation between emotion and rating
subdat%>%
  group_by(V1)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(V1,sentiment,Rating)%>%
  count()%>%
  ungroup()%>%
  group_by(sentiment)%>%
  summarize(correlation = cor(n,Rating))

```

```{r text analysis sentiment affin lexicon}
subdat %>%
  select(V1,Reviews)%>%
  group_by(V1)%>%
  unnest_tokens(output=word,input=Reviews)%>%
  inner_join(get_sentiments('afinn'))%>%
  summarize(reviewSentiment = mean(score))%>%
  ungroup()%>%
  summarize(min=min(reviewSentiment),max=max(reviewSentiment),median=median(reviewSentiment),mean=mean(reviewSentiment))

#Distribution of afinn lexicon scores
subdat %>%
  select(V1,Reviews)%>%
  group_by(V1)%>%
  unnest_tokens(output=word,input=Reviews)%>%
  inner_join(get_sentiments('afinn'))%>%
  summarize(reviewSentiment = mean(score))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+scale_fill_manual(values=c('tomato','seagreen'))+
  guides(fill=F)+
  theme_wsj()

```

```{r text analysis by city}
subdat= dat[,c("City", "Rating", "Reviews")]

#Positive words and negative words in different cities
subdat%>%
  group_by(City)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(City, sentiment)%>%
  count()%>%
  ggplot(aes(x=City,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+ coord_flip()

#Similar distribution of emotions
subdat%>%
  group_by(City)%>%
  unnest_tokens(output = word, input = Reviews)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment, City)%>%
  count()%>%
  ggplot(aes(x=City,y=n,fill=sentiment))+geom_bar(position = "fill", stat='identity')+guides(fill=F)+coord_flip()+theme_wsj()

#Sentiment mean, median, max and min 
subdat %>%
  select(City,Reviews)%>%
  group_by(City)%>%
  unnest_tokens(output=word,input=Reviews)%>%
  inner_join(get_sentiments('afinn'))%>%
  summarize(reviewMeanSentiment = mean(score), reviewMedianSentiment = median(score), reviewMaxSentiment = max(score),reviewMinSentiment = min(score))


```

```{r trends system}

#Look at correlation between rating and ranking
cor_rank=cor(dat$Ranking,dat$Rating,use="complete.obs")
cor_rank
finaldat
names(finaldat)

#Trends- number of vegan options and gluten-free options?
finaldat[get("Gluten Free Options") == 1, .N, by=city.name]
finaldat[get("Vegan Options") == 1, .N, by=city.name]
finaldat[get( "Healthy") == 1, .N, by=city.name]

head(finaldat)
```

